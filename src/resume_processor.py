import os
import pandas as pd
from cerebras.cloud.sdk import Cerebras
import json
import re
from typing import Dict, List, Optional
import time
from datetime import datetime

class ResumeProcessor:
    def __init__(self, api_key: str):
        """Initialize the resume processor with Cerebras API.""" # å¯æ¢ç”¨å…¶ä»–API
        self.client = Cerebras(api_key=api_key)
        self.model = "llama-4-scout-17b-16e-instruct"  # å¯æ¢ç”¨å…¶ä»–model
        self.processed_count = 0
        self.start_time = time.time()
        
    def extract_resume_info(self, resume_text: str, user_name: str) -> Dict:
        """Extract structured information from resume text using Cerebras API."""
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†ä¿¡æ¯æå–åŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹åŸºé‡‘ç»ç†ç®€å†ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

ç®€å†å†…å®¹ï¼š
{resume_text}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æå–ä¿¡æ¯ï¼Œå¦‚æœæŸé¡¹ä¿¡æ¯ä¸å­˜åœ¨ï¼Œè¯·ç”¨"-"è¡¨ç¤ºï¼š

1. åŸºæœ¬ä¿¡æ¯ï¼š
- æ€§åˆ«ï¼ˆç”·/å¥³ï¼‰
- å­¦å†ï¼ˆå–æœ€é«˜å­¦å†ï¼šæœ¬ç§‘/ç¡•å£«/åšå£«ç­‰ï¼‰
- æ¯•ä¸šé™¢æ ¡ï¼ˆæœ€é«˜å­¦å†çš„æ¯•ä¸šé™¢æ ¡ï¼‰

2. æ•™è‚²ç»å†ï¼ˆæ ¼å¼ï¼šå¤§å­¦åç§°|ä¸“ä¸šåç§°|å­¦ä½åç§°|å¼€å§‹æ—¶é—´|ç»“æŸæ—¶é—´ï¼‰ï¼š
- æ—¶é—´æ ¼å¼ç”¨yyyymmï¼Œå¦‚æœåªæœ‰å¹´ä»½ï¼Œç”¨01æœˆè¡¨ç¤ºï¼ˆå¦‚201901ï¼‰
- å¦‚æœä¿¡æ¯ç¼ºå¤±ï¼Œç”¨"-"æ›¿ä»£
- æŒ‰å­¦ä½çº§åˆ«åˆ†ç±»ï¼šå­¦å£«ã€ç¡•å£«ã€åšå£«ã€å…¶ä»–
- å‡½æˆç®—ä½œå­¦å£«å­¦ä½
- å¦‚æœç®€å†åªæœ‰æŸä¸€é¡¹å­¦å†ï¼Œå…¶ä»–é¡¹ç•™ç©º

3. å·¥ä½œç»å†ï¼ˆæ ¼å¼ï¼šå…¬å¸åç§°|èŒä½åç§°|å¼€å§‹æ—¶é—´|ç»“æŸæ—¶é—´ï¼‰ï¼š
- æ—¶é—´æ ¼å¼ç”¨yyyymmï¼Œå¦‚æœåªæœ‰å¹´ä»½ï¼Œç”¨01æœˆè¡¨ç¤º
- å¦‚æœä¿¡æ¯ç¼ºå¤±ï¼Œç”¨"-"æ›¿ä»£
- æœ€å¤šæå–5ä¸ªå·¥ä½œç»å†

4. å…¶ä»–ç‰¹å¾ï¼ˆç›´æ¥æ‘˜å½•åŸæ–‡æ–‡å­—ï¼Œä¸åšä¿®æ”¹ï¼‰ï¼š
- certificationï¼šè·å–çš„è¯ä¹¦ã€è¯æ˜ç­‰
- charityï¼šå‚ä¸æ…ˆå–„æ´»åŠ¨
- prizeï¼šè·å¥–ï¼ŒåŒ…æ‹¬ä¸šå†…/ä¸šå¤–è·å¥–ï¼Œè¡Œä¸šã€ç›‘ç®¡æœºæ„è®¤å¯ç­‰
- hobbyï¼šä¸ªäººçˆ±å¥½
- expert_inï¼šæ“…é•¿é¢†åŸŸï¼ŒåŒ…æ‹¬è¡Œä¸šä»ä¸šç»éªŒï¼Œç ”ç©¶é¢†åŸŸç­‰
- writingsï¼šæœ‰è‘—ä½œï¼ŒåŒ…æ‹¬å­¦æœ¯æ–‡ç« ã€ä¹¦ç±ã€åª’ä½“æŠ¥çº¸ç­‰
- part_time_jobï¼šå…¶ä»–å…¬å¸ã€è¡Œä¸šç»„ç»‡ç­‰çš„å…¼èŒç­‰
- social_activitiesï¼šç¤¾ä¼šæ´»åŠ¨

5. å…¶ä»–ä¿¡æ¯ï¼šç®€å†ä¸­å»é™¤ä»¥ä¸Šå·²ç»è¯†åˆ«å‡ºçš„é¡¹ç›®çš„å†…å®¹
- è¯·ä»…ä¿ç•™æœªå‡ºç°åœ¨ä¸Šè¿°â€œåŸºæœ¬ä¿¡æ¯â€ã€â€œæ•™è‚²ç»å†â€ã€â€œå·¥ä½œç»å†â€åŠâ€œå…¶ä»–ç‰¹å¾â€å„é¡¹ä¸­çš„å†…å®¹ã€‚
- è‹¥ä¿¡æ¯å®Œå…¨è¢«ä¸Šè¿°æå–é¡¹è¦†ç›–ï¼Œè¯·å¡«"-"

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "basic_info": {{
    "gender": "",
    "education": "",
    "graduate_school": ""
  }},
  "education_history": {{
    "bachelor": "",
    "master": "",
    "doctor": "",
    "other": ""
  }},
  "work_history": [
    "å…¬å¸åç§°|èŒä½åç§°|å¼€å§‹æ—¶é—´|ç»“æŸæ—¶é—´"
  ],
  "other_features": {{
    "certification": "",
    "charity": "",
    "prize": "",
    "hobby": "",
    "expert_in": "",
    "writings": "",
    "part_time_job": "",
    "social_activities": ""
  }},
  "other": ""
}}
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=2000,
                temperature=0.1
            )
            
            response_text = chat_completion.choices[0].message.content
            
            # Try to extract JSON from response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)
            else:
                print(f"  Warning: Could not parse JSON from response for {user_name}")
                return self._get_empty_structure()
                
        except Exception as e:
            print(f"  Error: API call failed for {user_name}: {str(e)}")
            return self._get_empty_structure()
    
    def _get_empty_structure(self) -> Dict:
        """Return empty structure when processing fails."""
        return {
            "basic_info": {
                "gender": "-",
                "education": "-",
                "graduate_school": "-"
            },
            "education_history": {
                "bachelor": "-",
                "master": "-",
                "doctor": "-",
                "other": "-"
            },
            "work_history": [],
            "other_features": {
                "certification": "-",
                "charity": "-",
                "prize": "-",
                "hobby": "-",
                "expert_in": "-",
                "writings": "-",
                "part_time_job": "-",
                "social_activities": "-"
            },
            "other": "-"
        }
    
    def _print_progress(self, current: int, total: int, user_name: str):
        """Print progress information."""
        elapsed = time.time() - self.start_time
        if current > 0:
            avg_time = elapsed / current
            remaining = (total - current) * avg_time
            eta_str = f"ETA: {remaining/60:.1f} min"
        else:
            eta_str = "ETA: calculating..."
        
        print(f"[{current}/{total}] Processing: {user_name} | Elapsed: {elapsed/60:.1f} min | {eta_str}")
    
    def process_dataframe(self, df: pd.DataFrame, start_idx: int = 0, end_idx: Optional[int] = None, 
                         checkpoint_interval: int = 50) -> pd.DataFrame:
        """Process the entire dataframe and fill in structured information."""
        
        if end_idx is None:
            end_idx = len(df)
            
        processed_df = df.copy()
        
        # Convert columns to object type to avoid dtype warnings
        string_columns = ['gender', 'education', 'graduate_school', 'æ•™è‚²1', 'æ•™è‚²2', 'æ•™è‚²3', 
                         'å·¥ä½œ1', 'å·¥ä½œ2', 'å·¥ä½œ3', 'å·¥ä½œ4', 'å·¥ä½œ5', 'certification', 'charity', 
                         'prize', 'hobby', 'expert_in', 'writings', 'part-time_job', 
                         'social_activities', 'OTHER']
        
        for col in string_columns:
            if col in processed_df.columns:
                processed_df[col] = processed_df[col].astype('object')
        
        records_with_resume = 0
        
        for idx in range(start_idx, min(end_idx, len(df))):
            row = df.iloc[idx]
            user_id = row['user_id']
            user_name = row['user_name']
            resume_minfo = str(row['resume_minfo']) if pd.notna(row['resume_minfo']) else ""
            resume_pinfo = str(row['resume_pinfo']) if pd.notna(row['resume_pinfo']) else ""
            
            self._print_progress(idx - start_idx + 1, end_idx - start_idx, user_name)
            
            # Skip if no resume information
            if not resume_minfo or resume_minfo == "-" or resume_minfo == "nan":
                print(f"  â†’ Skipping - no resume information")
                continue
            
            records_with_resume += 1
            
            # Combine resume information
            full_resume = f"{resume_minfo} {resume_pinfo}".strip()
            
            # Extract information using AI
            extracted_info = self.extract_resume_info(full_resume, user_name)
            
            # Update basic info if needed
            cd_changed = False
            if pd.isna(row['gender']) and extracted_info['basic_info']['gender'] != "-":
                processed_df.loc[idx, 'gender'] = extracted_info['basic_info']['gender']
                cd_changed = True
                
            if pd.isna(row['education']) and extracted_info['basic_info']['education'] != "-":
                processed_df.loc[idx, 'education'] = extracted_info['basic_info']['education']
                cd_changed = True
                
            if pd.isna(row['graduate_school']) and extracted_info['basic_info']['graduate_school'] != "-":
                processed_df.loc[idx, 'graduate_school'] = extracted_info['basic_info']['graduate_school']
                cd_changed = True
                
            if cd_changed:
                processed_df.loc[idx, 'CD_change'] = 1
                print(f"  â†’ Updated basic info (C/D columns)")
            
            # Fill education history
            education_cols = ['æ•™è‚²1', 'æ•™è‚²2', 'æ•™è‚²3']
            edu_count = 0
            print(extracted_info['education_history'])
            education_levels = ['bachelor', 'master', 'doctor']
            
            # Handle both dict and list formats for education_history
            if isinstance(extracted_info['education_history'], dict):
                for i, level in enumerate(education_levels):
                    edu = extracted_info['education_history'].get(level, "")
                    if edu and edu != "-":
                        processed_df.loc[idx, education_cols[i]] = edu
                        edu_count += 1
            elif isinstance(extracted_info['education_history'], list):
                # If it's a list, try to use the first few entries
                for i, edu in enumerate(extracted_info['education_history'][:3]):
                    if edu and edu != "-":
                        processed_df.loc[idx, education_cols[i]] = edu
                        edu_count += 1

            if edu_count > 0:
                print(f"  â†’ Added {edu_count} education record(s)")
            
            # Fill work history
            work_cols = ['å·¥ä½œ1', 'å·¥ä½œ2', 'å·¥ä½œ3', 'å·¥ä½œ4', 'å·¥ä½œ5']
            work_count = 0
            for i, work in enumerate(extracted_info['work_history'][:5]):
                if work and work != "-":
                    processed_df.loc[idx, work_cols[i]] = work
                    work_count += 1
            if work_count > 0:
                print(f"  â†’ Added {work_count} work record(s)")
            
            # Fill other features
            feature_count = 0
            for feature, value in extracted_info['other_features'].items():
                if value and value != "-":
                    processed_df.loc[idx, feature] = value
                    feature_count += 1
            if feature_count > 0:
                print(f"  â†’ Added {feature_count} feature(s)")
            
            # Fill other information
            if extracted_info['other'] and extracted_info['other'] != "-":
                processed_df.loc[idx, 'OTHER'] = extracted_info['other']
                print(f"  â†’ Added other information")
            
            self.processed_count += 1
            
            # Save checkpoint periodically
            if (idx - start_idx + 1) % checkpoint_interval == 0:
                checkpoint_file = f"checkpoint_{idx+1}.xlsx"
                processed_df.to_excel(checkpoint_file, index=False)
                print(f"  â†’ Checkpoint saved: {checkpoint_file}")
            
            # Rate limiting
            time.sleep(0.3)  # Slightly faster than before
        
        print(f"\nğŸ“Š Processing Summary:")
        print(f"- Total records examined: {end_idx - start_idx}")
        print(f"- Records with resume data: {records_with_resume}")
        print(f"- Records successfully processed: {self.processed_count}")
        
        return processed_df

def main():
    print("ğŸš€ Starting Full Resume Processing Pipeline")
    print(f"â° Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # Set up API key - get from environment variable
    api_key = os.environ.get("CEREBRAS_API_KEY")   # or replace it with your API key 
    if not api_key:
        print("âŒ Error: Please set CEREBRAS_API_KEY environment variable")
        print("Example: export CEREBRAS_API_KEY='your_api_key_here'")
        return
    
    # File paths - update these to your local files
    input_file = "example_data/manager_cv.xlsx"  # Update this path
    output_file = "output/processed_manager_cv.xlsx"  # Update this path
    
    try:
        # Load the Excel file
        print("ğŸ“‚ Loading Excel file...")
        df = pd.read_excel(input_file)
        print(f"âœ… Loaded {len(df)} records")
        
        # Count records with resume data
        resume_count = df['resume_minfo'].notna().sum() - (df['resume_minfo'] == '-').sum()
        print(f"ğŸ“‹ Records with resume data: {resume_count}")
        print(f"â±ï¸  Estimated processing time: {resume_count * 0.3 / 60:.1f} minutes")
        
        # Initialize processor
        processor = ResumeProcessor(api_key)
        
        # Process ALL records
        print("\nğŸ”„ Starting processing...")
        processed_df = processor.process_dataframe(df, checkpoint_interval=100)
        
        # Save the final processed dataframe
        print(f"\nğŸ’¾ Saving final processed data to {output_file}...")
        processed_df.to_excel(output_file, index=False)
        print("âœ… Processing completed successfully!")
        
        # Show final summary
        changes_count = processed_df['CD_change'].sum()
        total_time = time.time() - processor.start_time
        
        print(f"\nğŸ“ˆ Final Summary:")
        print(f"- Total records: {len(processed_df)}")
        print(f"- Records with C/D updates: {changes_count}")
        print(f"- Total processing time: {total_time/60:.1f} minutes")
        print(f"- Average time per record: {total_time/len(df):.2f} seconds")
        print(f"ğŸ‰ Output saved to: {output_file}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  Processing interrupted by user")
        print("ğŸ’¾ Check for checkpoint files in the directory")
    except Exception as e:
        print(f"\nâŒ Error: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

